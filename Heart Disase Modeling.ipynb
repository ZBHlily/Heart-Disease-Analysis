{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350f963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix \n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5369a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4458a887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "before: (303, 14)\n",
      "after: (302, 14)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('/Users/lilyliang/Downloads/447 notes/dataset.csv')\n",
    "df.head()\n",
    "\n",
    "# check if there are duplicate rows \n",
    "print(df.duplicated().sum())\n",
    "\n",
    "print(\"before:\",df.shape)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"after:\",df.shape)\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2342bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['age',\n",
    " 'sex',\n",
    " 'cp',\n",
    " 'trestbps',\n",
    " 'chol',\n",
    " 'fbs',\n",
    " 'restecg',\n",
    " 'thalach',\n",
    " 'exang',\n",
    " 'oldpeak',\n",
    " 'slope',\n",
    " 'ca',\n",
    " 'thal']\n",
    "\n",
    "X = df[selected_features] # features\n",
    "\n",
    "y = df['target'] # target values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea10417",
   "metadata": {},
   "source": [
    "### Train base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c92c8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic Regression': {'Training Accuracy': 0.8755186721991701, 'Testing Accuracy': 0.8524590163934426}, 'Decision Trees': {'Training Accuracy': 1.0, 'Testing Accuracy': 0.8032786885245902}, 'Random Forest': {'Training Accuracy': 1.0, 'Testing Accuracy': 0.8524590163934426}, 'XGBoost': {'Training Accuracy': 1.0, 'Testing Accuracy': 0.8360655737704918}, 'SVM': {'Training Accuracy': 0.6514522821576764, 'Testing Accuracy': 0.7049180327868853}, 'KNN': {'Training Accuracy': 0.7593360995850622, 'Testing Accuracy': 0.6557377049180327}, 'Naive Bayes': {'Training Accuracy': 0.8174273858921162, 'Testing Accuracy': 0.8852459016393442}}\n"
     ]
    }
   ],
   "source": [
    "def evaluate_models(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Decision Trees': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'XGBoost': XGBClassifier(),\n",
    "        'SVM': SVC(),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for name, model in models.items():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on training and testing sets\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate training and testing accuracy\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Store results in the dictionary\n",
    "        results[name] = {'Training Accuracy': train_accuracy, 'Testing Accuracy': test_accuracy}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage example:\n",
    "# Assuming X and y are your features and target variable\n",
    "results = evaluate_models(X, y)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b4079b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAGoCAYAAABbkkSYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAAsTAAALEwEAmpwYAABRV0lEQVR4nO3dd5xcZfX48c9hE0I1lESkSZHeIhIIRSWASCcgXZqgNIUQQCWIQkBRrAhKEaWI0nuRryhCBASkKD8EpBNN6AQSQks9vz+eu+uw2SQbmMnsZj/v1yuv7MzcmTkzd2f2nvuc5zyRmUiSJEmSPrx5mh2AJEmSJM0tTLAkSZIkqU5MsCRJkiSpTkywJEmSJKlOTLAkSZIkqU5MsCRJkiSpTkywJKmOImKTiHgqIt6KiJ0+4GOcExHfqbl8WES8XD3m4vV4ju4mIgZHxJhObjsiIn7f6JjmhGofr1jvbZslIpaPiIyIXk16/i7/Hknq/kywJNVVRIyMiDciok+zY2mSk4FfZuZCmXld+xsjYlREvBsREyJiXETcHRGHRkTb93FmHpqZ36227w38DPh89ZhjZ/UcjRQRF0bE92axTUbEK7UH0RHRu7purl58MSI+Ux3EvxURb1fvxVs1/z4+O49X7eNn671tV9TufZpWfU5aL+/9AR5vZER8pfa6Rr1HEbFIRJwfES9Vn+0nI2J4J+87y8+UpO7FBEtS3UTE8sBngAR2nMPP3ZQz4h1YDnh0FtvskJkLV9ueChwLnDeDbZcA5mv3mJ15jg7NwffpDWCbmsvbVNfN1TLzzuogfiFgzerqRVqvy8z/tm7bhX5nu4Sa92gh4L+Uz0nrdRc3O75ZOA1YCFgd6Ev5/nu6qRFJahoTLEn1tB9wL3AhsH/tDRGxbERcExGvRsTYiPhlzW0HRcS/qzO/j0XEp6rrMyJWqtmu7Uxva8lYRBwbES8BF0TEohFxU/Ucb1Q/L1Nz/8Ui4oKIeKG6/brq+kciYoea7XpHxGsRsW5HL7KK9+mIeD0iboiIparrnwFWBG6szrrPdBQvM8dn5g3AHsD+EbFW7euMiFWAJ6rNx0XEbR09R0T0jYjzIuLFiHi+um9L9Vhfioi/RcRpETEWGFHd5ycR8d8opYfnRMT87d7XY6oRpxcj4oDqtoOBvYFvVs9940xe3u8ovw+t9gMuavc+LlW9f69X7+dBNbfNX70Pb0TEY8D6Hdz36mpfPxcRQzsKIiLmi4jfV79z4yLi/ohYYgbbrl6NeoyLiEcjYsea2y6MiDMj4g/V7+nfI+ITM3n9HT3+iIi4qornTeBLEbFBRNxTPeeLEfHLiJi35j5tn4FZxTCb234+Ip6IiPERcVZE/DXajfbUbNuZGA+NUrY6rnreqG5rqX7XXouIZ4HtZuc9qx5jnogYHhHPVPvxiohYrLqtw/0bEadQTvb8svpd/WUj3yPK7+clmflGZk7LzMcz86qax1otIv5c/a4/ERG7V9d3+JmK8r32fBXXExGxxey+b5KaxwRLUj3tB1xc/duq9UA2ysH+TcB/gOWBpYHLqtt2A0ZU9/0I5czv2E4+38eAxSgjOgdTvtMuqC5/HHgX+GXN9r8DFqCMLHyUctYZyoH/PjXbbQu8mJn/bP+EEbE58ANgd2DJ6jVdBpCZn+D9Z94nduZFZOZ9wBjKAWHt9U/y/lGQzWfwHBcCU4CVgHWBzwO1B4KDgGcpo2GnUEbNVgE+Wd1naeCEmu0/RjkLvzTwZeDMiFg0M8+l7NsfVc+9AzN2HfDZKKVTi1av7fp221xWve6lgF2B71fvL8CJwCeqf1tRk7BHKae8Efh/VYxbAMMiYqsO4ti/ei3LAosDh1J+L94nSinmjcCfKL8bRwAXR8SqNZvtCZwELEoZnThlJq9/RoYAVwGLUN7LqcBRQD9go+q1fHUm95+dGDrcNiL6VTEcR3lPngA2nsnjdCbG7SlJxjqUz0brvjioum1dYCBlP8+uI4CdgE0pvytvAGdWt3W4fzPzeOBO4PDqd/XwGTx2vd6je4FTIuKAiFi59oaIWBD4M3AJ5XdrT+CsiFijo89U9Tt3OLB+NdK9FTBqVm+SpK7DBEtSXUTEpymJzRWZ+SDwDPDF6uYNKAdG38jMtzPzvcy8q7rtK5SDi/uzeDoz/9PJp50GnJiZEzPz3cwcm5lXZ+Y7mTmBcrC0aRXfkpQytUOrs8yTM/Ov1eP8Htg2Ij5SXd6Xkox1ZG/g/Mz8R5XcHAdsFKU88sN4gZIszpYqid0WGFa9t69QEsc9ax87M3+RmVOA9yjJ6FGZ+Xr1Pn2/3faTgZOr9+hm4C2gNtHojPcoCcse1b8bquta414W2AQ4tvp9eAj4Df8b9dodOKWKcTRwRs1jrw/0z8yTM3NSNafm1+1eQ+1rWRxYKTOnZuaDmflmB9ttSCnxOrV6zNsoJwX2qtnm2sy8r3ofL6YkqLPrnsy8rhrleLeK597MnJKZo4BfUf3OzsDsxDCjbbcFHs3Ma6rbzgBemtGDdDLGUzNzXFUCeXvNc+0O/DwzR2fm65STE7PrUOD4zBxTfeZGALtGKbHs7P6dkbq8R1QJOSUxeizKiGxriez2wKjMvKB6D/8JXA3sNoPHmgr0AdaIiN6ZOSozn5mN1ySpyaz/llQv+wN/yszXqsuXVNedRjm7/J/qQKW9ZSnJ2AfxambWHrQvUD3f1pQz0gALVyNoywKvZ+Z084Ay84WI+BuwS0RcS0nEjpzBcy4F/KPmvm9FKb1bmg93lnlp4PUPcL/lgN7Ai1VVFpSTZ6Nrtqn9uT9lFO/Bmu0DaKnZZmy7ffUOJfmYXRdRDqiDMs+s1lKU/TGh5rr/UEY5Wm8f3e62VssBS0XEuJrrWigjFu39jrLvL4uIRSjJ9PGZObmDeEZn5rR2z7l0zeXaA+wP+p7UviailIH+jPK6F6D8XX5wJvefnRhmtO373tvMzJhJh8ZOxtip5+L9+7GzlgOujYjafTOVMiLb2f07I3V5jzLzXcqJiu9XJ2qGA1dGaWqyHDCo3e9rL2ZwEiczn46IYZREcs2IuAU4OjNf6ORrktRkjmBJ+tCizN/ZHdg0ShetlyglRQMiYgDlQOXj0fGk/tGUMrCOvEM5oGv1sXa3t+9IdwxlpGVQZn4E+GxriNXzLFYdhHXkt5Qywd0oowzPz2C7FygHTOWBS/nP4sCMtp+liFifciB/16y27cBoYCLQLzMXqf59JDPXrNmm9n16jVIit2bN9n2zNBbojNnpAngnpYxyCaZ/bS9Q9sfCNdd9nP+9jy9SDpxrb2s1GniuJv5FMnPhzNx2umDLKNxJmbkGpcRre94/N6w2nmWjpptju3jqpf37dzbwOLBy9Tv7LcrvayO9CNTOTYzayx34MDHObD921mhgm3b7e77MfH4W+/fDdKyc3feoTTWC9n1gQWCFKv6/tot/ocw8bEZxZuYlmdlaFZDADz/Ea5E0h5lgSaqHnShnlNeglNh8ktJN607Kwc59lAOWUyNiwWpi+ibVfX8DfD0i1otipYhoTWAeAr5YTZTfmpmXTgEsTEkexlWT4E9svSEzXwT+jzL3YdEojSw+W3Pf64BPUUau3teMoZ1LgQMi4pNRmlh8H/h7VTo1WyLiIxGxPWUu0u8z81+z+xjV6/oT8NPq8eaJiE9ERIfvVTVC82vgtIj4aBXH0jOYv9SRlylNNjoTWwI7ADtWP9feNhq4G/hB9fuwDmW+V+v6VVcAx1X7ahlKCVar+4AJVSOA+avfj7WqRPV9ImKziFi7GsV8k1JSNq39dsDfKQn9N6vfjcFV7Jd15rV+CAtXcb0VEasBh81i+3r4A7B2ROxUnfT4GtOfvKhXjFcAQyNimWouXqdal7dzDmV+03IAEdE/IoZUP89s/3b6d7UDs/UeRcR3ImL9iJg3IuajfI+Mo8zduglYJSL2rX63elfbrt5RnBGxakRsXn2/vEf5Tuvod1ZSF2WCJake9gcuyMz/ZuZLrf8oDSb2ppzt3oHSUOG/lMYGewBk5pWUuVKXABMoiU7rXKQjq/uNqx7nulnE8XNgfsoozb3AH9vdvi/lAOxx4BVgWOsNVYnP1ZQzztfM6Aky81bgO9W2L1JG3zqa+zMzN0bEBMqZ7eMp5VcHzOZj1NoPmBd4jNIA4CrKyNGMHEuZ0H9vlG52t9L5OVbnUeaGjIuqC+PMZOajmTmjlvJ7UZqevABcS5lPd2t120mUcrLnKAlkWzlVZk6ljFR8srr9NUqi3reD5/gY5f14E/g38Fc6KM3KzEmU37Vtqsc7C9gvMx+f1Wv8kL5Omas4gZL4Xt7g56Mq490N+BGlocwawAOUkdB6x/hr4BZKQ5J/MJPP1kycTpnD96fqc3MvpXELzHz/nk6Zq/VGRJzBbPgA71FSGuy8Rvl93hLYLjPfqspgP0/5nniBUpb4Q8o8K5j+M9WH0ojmtWrbj1LmekrqJqLdSUVJ6rEi4gRglczcZ5YbS3OJqixyDLB3Zt7e7Hi6It8jSbPDESxJoqyRRSlRO7fZsUiNFhFbRWmh34f/zam6t8lhdSm+R5I+KBMsST1elAVuRwP/l5l3NDseaQ7YiNK98zVKaeROVZms/sf3SNIHYomgJEmSJNWJI1iSJEmSVCfdbqHhfv365fLLL9/sMCRJkiT1YA8++OBrmdm//fXdLsFafvnleeCBB5odhiRJkqQeLCL+09H1lghKkiRJUp2YYEmSJElSnZhgSZIkSVKddLs5WJIkSVIzTZ48mTFjxvDee+81OxTNAfPNNx/LLLMMvXv37tT2JliSJEnSbBgzZgwLL7wwyy+/PBHR7HDUQJnJ2LFjGTNmDCussEKn7mOJoCRJkjQb3nvvPRZffHGTqx4gIlh88cVna7TSBEuSJEmaTSZXPcfs7msTLEmSJEmqE+dgSZIkSR/Cqaf+nIkTx9ft8fr06cvw4cNmePvYsWPZYostAHjppZdoaWmhf//+ANx3333MO++8M7zvAw88wEUXXcQZZ5wx0xg23nhj7r777tkPfgaGDRvGlVdeyejRo5lnnrl7jKdhCVZEnA9sD7ySmWt1cHsApwPbAu8AX8rMfzQqHkmSJKkRJk4cz4gRJ9bt8UaMOGmmty+++OI89NBD1bYjWGihhfj617/edvuUKVPo1avjw/yBAwcycODAWcZQz+Rq2rRpXHvttSy77LL89a9/ZbPNNqvbY9ea2euekxqZPl4IbD2T27cBVq7+HQyc3cBYJEmSpLnWl770JQ499FAGDRrEN7/5Te677z422mgj1l13XTbeeGOeeOIJAEaOHMn2228PlOTswAMPZPDgway44orvG9VaaKGF2rYfPHgwu+66K6utthp77703mQnAzTffzGqrrcZ6663H0KFD2x63vZEjR7Lmmmty2GGHcemll7Zd//LLL7PzzjszYMAABgwY0JbUXXTRRayzzjoMGDCAfffdt+31XXXVVR3G95nPfIYdd9yRNdZYA4CddtqJ9dZbjzXXXJNzzz237T5//OMf+dSnPsWAAQPYYostmDZtGiuvvDKvvvoqUBLBlVZaqe3yB9WwFC8z74iI5WeyyRDgoix76N6IWCQilszMFxsVkyRJkjS3GjNmDHfffTctLS28+eab3HnnnfTq1Ytbb72Vb33rW1x99dXT3efxxx/n9ttvZ8KECay66qocdthh06339M9//pNHH32UpZZaik022YS//e1vDBw4kEMOOYQ77riDFVZYgb322muGcV166aXstddeDBkyhG9961tMnjyZ3r17M3ToUDbddFOuvfZapk6dyltvvcWjjz7K9773Pe6++2769evH66+/PsvX/Y9//INHHnmkrY36+eefz2KLLca7777L+uuvzy677MK0adM46KCD2uJ9/fXXmWeeedhnn324+OKLGTZsGLfeeisDBgxoK7f8oJpZALk0MLrm8pjqOkmSJEmzabfddqOlpQWA8ePHs9tuu7HWWmtx1FFH8eijj3Z4n+22244+ffrQr18/PvrRj/Lyyy9Pt80GG2zAMssswzzzzMMnP/lJRo0axeOPP86KK67YltTMKMGaNGkSN998MzvttBMf+chHGDRoELfccgsAt912G4cddhgALS0t9O3bl9tuu43ddtuNfv36AbDYYovN8nVvsMEG71uj6owzzmDAgAFsuOGGjB49mqeeeop7772Xz372s23btT7ugQceyEUXXQSUxOyAAw6Y5fPNSvOLFDshIg6mlBHy8Y9/vMnRaG5Q78mo9TKrSa09WVfdZ+B+m5muut/cZ5LmRgsuuGDbz9/5znfYbLPNuPbaaxk1ahSDBw/u8D59+vRp+7mlpYUpU6Z8oG1m5JZbbmHcuHGsvfbaALzzzjvMP//8MywnnJFevXoxbdo0oJTyTZo0qe222tc9cuRIbr31Vu655x4WWGABBg8ePNM1rJZddlmWWGIJbrvtNu677z4uvvji2Yqrw1g/9CN8cM8Dy9ZcXqa6bjqZeS5wLsDAgQOz8aFpblfvyaj1MqtJrT1ZV91n4H6bma6639xnkuZ248ePZ+mlS3HYhRdeWPfHX3XVVXn22WcZNWoUyy+/PJdffnmH21166aX85je/aRvhevvtt1lhhRV455132GKLLTj77LMZNmxYW4ng5ptvzs4778zRRx/N4osvzuuvv85iiy3G8ssvz4MPPsjuu+/ODTfcwOTJk2f4uhdddFEWWGABHn/8ce69914ANtxwQ7761a/y3HPPtZUIto5ifeUrX2GfffZh3333bRsB/DCamWDdABweEZcBg4Dxzr+SJElSd9OnT9+6nrjp06fvh36Mb37zm+y///5873vfY7vttqtDVO83//zzc9ZZZ7H11luz4IILsv7660+3zTvvvMMf//hHzjnnnLbrFlxwQT796U9z4403cvrpp3PwwQdz3nnn0dLSwtlnn81GG23E8ccfz6abbkpLSwvrrrsuF154IQcddBBDhgxhwIABbc/Zka233ppzzjmH1VdfnVVXXZUNN9wQgP79+3PuuefyhS98gWnTpvHRj36UP//5zwDsuOOOHHDAAXUpDwQgMxvyD7gUeBGYTJlf9WXgUODQ6vYAzgSeAf4FDOzM46633nopfVgjRoxIyC73b8SIEc1+a7qsrrrP3G8z11X3m/tM0ofx2GOPNTuELmHChAmZmTlt2rQ87LDD8mc/+1mTI/pg7r///vz0pz8902062ufAA9lBvtLILoIzbiVSbk/ga416fkmSJEmN8+tf/5rf/va3TJo0iXXXXZdDDjmk2SHNtlNPPZWzzz67LnOvWnWLJheSJEmSupajjjqKo446qtlhfCjDhw9n+PDhdX3MZrZplyRJkqS5igmWJEmSJNWJCZYkSZIk1YkJliRJkiTViU0uJEmSpA/h56eeyviJE+v2eH379GHYTBovjB07li222AKAl156iZaWFvr37w/Afffdx7zzzjvTxx85ciTzzjsvG2+8MQDnnHMOCyywAPvtt19d4n/ttddYcskl+cUvfsGhhx5al8fsTkywJEmSpA9h/MSJnDhiRN0e76RZPNbiiy/OQw89BMCIESNYaKGF+PrXv97pxx85ciQLLbRQW4JV7yToyiuvZMMNN+TSSy9taII1ZcoUevXqeumMJYKSJElSN/fggw+y6aabst5667HVVlvx4osvAnDGGWewxhprsM4667DnnnsyatQozjnnHE477TQ++clPcueddzJixAh+8pOfADB48GCOPfZYNthgA1ZZZRXuvPNOAN555x1233131lhjDXbeeWcGDRrEAw880GEsl156KT/96U95/vnnGTNmTNv1F110Eeussw4DBgxg3333BeDll19m5513ZsCAAQwYMIC7776bUaNGsdZaa7Xd7yc/+QkjqqRz8ODBDBs2jIEDB3L66adz4403MmjQINZdd10+97nP8fLLLwPw1ltvccABB7D22muzzjrrcPXVV3P++eczbNiwtsf99a9/3ZA2810v5ZMkSZLUaZnJEUccwfXXX0///v25/PLLOf744zn//PM59dRTee655+jTpw/jxo1jkUUW4dBDD33fqNdf/vKX9z3elClTuO+++7j55ps56aSTuPXWWznrrLNYdNFFeeyxx3jkkUf45Cc/2WEso0eP5sUXX2SDDTZg99135/LLL+eYY47h0Ucf5Xvf+x533303/fr14/XXXwdg6NChbLrpplx77bVMnTqVt956izfeeGOmr3fSpEltyd0bb7zBvffeS0Twm9/8hh/96Ef89Kc/5bvf/S59+/blX//6V9t2vXv35pRTTuHHP/4xvXv35oILLuBXv/rVh3nrO2SCJUmSJHVjEydO5JFHHmHLLbcEYOrUqSy55JIArLPOOuy9997stNNO7LTTTp16vC984QsArLfeeowaNQqAu+66iyOPPBKAtdZai3XWWafD+15++eXsvvvuAOy5554ceOCBHHPMMdx2223stttu9OvXD4DFFlsMgNtuu42LLroIgJaWFvr27TvLBGuPPfZo+3nMmDHssccevPjii0yaNIkVVlgBgFtvvZXLLrusbbtFF10UgM0335ybbrqJ1VdfncmTJ7P22mt36j2ZHSZYkiRJUjeWmay55prcc8890932hz/8gTvuuIMbb7yRU045pW1EZ2b69OkDlIRnypQpsxXLpZdeyksvvcTFF18MwAsvvMBTTz01W4/Rq1cvpk2b1nb5vffee9/tCy64YNvPRxxxBEcffTQ77rgjI0eObCslnJGvfOUrfP/732e11VbjgAMOmK24Oss5WJIkSVI31qdPH1599dW2BGvy5Mk8+uijTJs2jdGjR7PZZpvxwx/+kPHjx/PWW2+x8MILM2HChNl6jk022YQrrrgCgMcee6zDRO3JJ5/krbfe4vnnn2fUqFGMGjWK4447jksvvZTNN9+cK6+8krFjxwK0lQhuscUWnH322UAZeRs/fjxLLLEEr7zyCmPHjmXixIncdNNNM4xr/PjxLL300gD89re/bbt+yy235Mwzz2y73DoqNmjQIEaPHs0ll1zCXnvtNVvvQWc5giVJkiR9CH379Jll57/ZfbzZMc8883DVVVcxdOhQxo8fz5QpUxg2bBirrLIK++yzD+PHjyczGTp0KIsssgg77LADu+66K9dffz2/+MUvOvUcX/3qV9l///1ZY401WG211VhzzTXp27fv+7a59NJL2Xnnnd933S677MIee+zBCSecwPHHH8+mm25KS0sL6667LhdeeCGnn346Bx98MOeddx4tLS2cffbZbLTRRpxwwglssMEGLL300qy22mozjGvEiBHstttuLLroomy++eY899xzAHz729/ma1/7GmuttRYtLS2ceOKJbaWPu+++Ow899FBb2WC9mWBJkiRJH8LM1qxqtNqSuDvuuGO62++6667prltllVV4+OGH2y5/5jOfaft55MiRbT/369evbQ7WfPPNx+9//3vmm28+nnnmGT73uc+x3HLLve9xTzzxxOmea5111uHf//43APvvvz/777//+25fYokluP7666e739ChQxk6dOh019fGBzBkyBCGDBky3XYLLbTQ+0a0at11110N6R7YygRLkiRJ0ky98847bLbZZkyePJnM5KyzzprlgsZdzbhx49hggw0YMGBA20LNjWCCJUmSJGmmFl544Rmue9VdLLLIIjz55JMNfx6bXEiSJEmzKTObHYLmkNnd1yZYkiRJ0myYb775GDt2rElWD5CZjB07lvnmm6/T97FEUJIkSZoNyyyzDGPGjOHVV19tdiiaA+abbz6WWWaZTm9vgiVJkiTNht69e7PCCis0Owx1UZYISpIkSVKdmGBJkiRJUp2YYEmSJElSnZhgSZIkSVKdmGBJkiRJUp2YYEmSJElSnZhgSZIkSVKduA6WJEmSJAB+fuqpjJ84sdlhTKdvnz4MGz682WF0igmWJEmSJADGT5zIiSNGNDuM6ZzUBWOaEUsEJUmSJKlOHMGqg1NP/TkTJ45vdhjT6dOnL8OHD2t2GJIkSVKPYYJVBxMnjmfEiBObHcZ0Row4qdkhSJIkST2KJYKSJEmSVCcmWJIkSZJUJyZYkiRJklQnJliSJEmSVCcmWJIkSZJUJ3YRnIu1TJ7MSSd1vU6C3Wklbqkz/KxJkqRWJlhzsam9e7sStzQH+FmTJEmtLBGUJEmSpDoxwZIkSZKkOrFEUJLU4zhvTpLUKCZYkqQex3lzkqRGsURQkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEJheSJEnSHHTqqT9n4sTxzQ5DDdLQBCsitgZOB1qA32Tmqe1u/zjwW2CRapvhmXlzI2OSJEmSmmnixPGMGHFis8Po0IgRXW8Ji+6mYSWCEdECnAlsA6wB7BURa7Tb7NvAFZm5LrAncFaj4pEkSZKkRmvkHKwNgKcz89nMnARcBgxpt00CH6l+7gu80MB4JEmSJKmhGlkiuDQwuubyGGBQu21GAH+KiCOABYHPdfRAEXEwcDDAxz/+8boHKnUVLZMnc9JJXW9ovm+fPgwbPrzZYUiSJHV5zW5ysRdwYWb+NCI2An4XEWtl5rTajTLzXOBcgIEDB2YT4pTmiKm9e3PiiBHNDmM6J3XBmCRJkrqiRpYIPg8sW3N5meq6Wl8GrgDIzHuA+YB+DYxJkiRJkhqmkQnW/cDKEbFCRMxLaWJxQ7tt/gtsARARq1MSrFcbGJMkSZIkNUzDEqzMnAIcDtwC/JvSLfDRiDg5InasNjsGOCgi/h9wKfClzLQEUJIkSVK31NA5WNWaVje3u+6Emp8fAzZpZAySJEmSNKc0skRQkiRJknoUEyxJkiRJqhMTLEmSJEmqExMsSZIkSaoTEyxJkiRJqhMTLEmSJEmqk4a2aZckSVJjnXrqz5k4cXyzw5hOnz59GT58WLPDkOY4EyxJkqRubOLE8YwYcWKzw5jOiBEnNTsEqSksEZQkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ66dXsACRJkmbl56eeyviJE5sdxnT69unDsOHDmx2GpC7EBEuSJHV54ydO5MQRI5odxnRO6oIxSWouSwQlSZIkqU5MsCRJkiSpTkywJEmSJKlOTLAkSZIkqU5MsCRJkiSpTkywJEmSJKlOTLAkSZIkqU5MsCRJkiSpTkywJEmSJKlOTLAkSZIkqU5MsCRJkiSpTno1OwBJkiTNfVomT+akk05qdhgd6tunD8OGD292GJpLmWBJkiSp7qb27s2JI0Y0O4wOndRF49LcwQRLkiS1OfXUnzNx4vhmhyFJ3ZYJliRJajNx4nhGjDix2WFMZ8SIrllqJknt2eRCkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqpKEJVkRsHRFPRMTTETF8BtvsHhGPRcSjEXFJI+ORJEmSpEbq1agHjogW4ExgS2AMcH9E3JCZj9VsszJwHLBJZr4RER9tVDySJEmS1GizHMGKiIMjou8HeOwNgKcz89nMnARcBgxpt81BwJmZ+QZAZr7yAZ5HkiRJkrqEzpQIngO8GBGXR8R21chUZywNjK65PKa6rtYqwCoR8beIuDcitu7ogaok74GIeODVV1/t5NNLkiRJ0pzVmQRrF+Aa4PPADcDzEfGziFizDs/fC1gZGAzsBfw6IhZpv1FmnpuZAzNzYP/+/evwtJIkSZJUf7NMsDLz2szcB1gb+AvwUWAY8HBEnDiTuz4PLFtzeZnqulpjgBsyc3JmPgc8SUm4JEmSJKnb6cwcrB0j4lrgGeBzwD3AfsCvgG/M5K73AytHxAoRMS+wJ2UErNZ1lNErIqIfpWTw2dl7CZIkSZLUNXSmi+B1wNvABcBZmfkwQET8P2D1Gd0pM6dExOHALUALcH5mPhoRJwMPZOYN1W2fj4jHgKnANzJz7Id5QZIkSZLULJ1JsA4HfpeZE2qvzMx/AZvN7I6ZeTNwc7vrTqj5OYGjq3+SJEmS1K11dqHhXVt/iIgDI+JrDYpHkiRJkrqtziRY3wX61FyeFzi5MeFIkiRJUvfVmQRrHkrnwFZLANGYcCRJkiSp++rMHKx7gOMjYg1KYrUTcGsjg5IkSZKk7qgzCdaRwE3A7tXlJynrYEmSJEmSaswywcrMp6rRq1Wrq57IzKmNDUuSJEmSup9ZJlgREZTRq7WB+arrMjOPaXBskiRJktStdKZE8EzgUCD5X3OLBEywJEmSJKlGZ7oI7gxcUv18JHA7pXW7JEmSJKlGZxKsRYE7q59fBK4CDm5YRJIkSZLUTXWmRPClaruXgN9QFhp+s5FBSZIkSVJ31JkRrG8DTwNHA+8B47FNuyRJkiRNZ6YJVkS0AOsCkzLz8sz8WGYumZmXzZnwJEmSJKn7mGmCVa13tRPwiTkSjSRJkiR1Y52ZgzUSOCEi+lCaXACQmdc0KihJkiRJ6o46k2AdUP1/RvV/UNbBamlIRJIkSZLUTXUmwTqZklBJkiRJkmZilglWZo6YA3FIkiRJUrc3ywQrIm7r4OrMzC0aEI8kSZIkdVudKREc3MF1lgxKkiRJUjudSbD61/y8KDCCmm6CkiRJkqRiputgVbLm35vAE8D+jQxKkiRJkrqjzoxgvcb0JYFPNCAWSZIkSerWOpNg3cH/EqypwCjgJ40KSJIkSZK6q860aR88B+KQJEmSpG5vlnOwIuKiiBhRc/mkiLiooVFJkiRJUjfUmSYXuwD/qbn8H+ALjQlHkiRJkrqvziRY44BNay4PBsY3IhhJkiRJ6s460+TiRuDgiNiquvxR4NzGhSRJkiRJ3VNnEqxvAPMC21eXLwS+2aiAJEmSJKm76kwXwQnAgXMgFkmSJEnq1jrTRXBkRPys5vJpEXF7Y8OSJEmSpO6nM00uNgD+VXP5YWBQY8KRJEmSpO6rMwnWK8AXImKBiFgQ2LW6TpIkSZJUozNNLi4FjgXerC7PA/ygYRFJkiRJUjfVmQTrBOBd/tdF8AZgvoZFJEmSJEnd1CxLBDNzMnAFcDOwEHAScFyD45IkSZKkbmeGI1gRsTKwO7AHsCYQQAJ/AH43R6KTJEmSpG5kZiWCT1ASqheBM4H7gIuA32TmDXMgNkmSJEnqVmY1B2sa8FfgNkrCJUmSJEmagZnNwToCuJtSIng18A/KiNb6EbH4HIhNkiRJkrqVGSZYmXlmZm4KLAscTUmwAI4HXpoDsUmSJElSt9KZLoIvZubpmbkJsBzwdeDBhkcmSZIkSd3MLBOsWpk5JjN/lpkbNiogSZIkSequZivBkiRJkiTNmAmWJEmSJNWJCZYkSZIk1YkJliRJkiTVSUMTrIjYOiKeiIinI2L4TLbbJSIyIgY2Mh5JkiRJaqSGJVgR0QKcCWwDrAHsFRFrdLDdwsCRwN8bFYskSZIkzQmNHMHaAHg6M5/NzEnAZcCQDrb7LvBD4L0GxiJJkiRJDdfIBGtpYHTN5THVdW0i4lPAspn5h5k9UEQcHBEPRMQDr776av0jlSRJkqQ6aFqTi4iYB/gZcMysts3MczNzYGYO7N+/f+ODkyRJkqQPoJEJ1vPAsjWXl6mua7UwsBYwMiJGARsCN9joQpIkSVJ31cgE635g5YhYISLmBfYEbmi9MTPHZ2a/zFw+M5cH7gV2zMwHGhiTJEmSJDVMwxKszJwCHA7cAvwbuCIzH42IkyNix0Y9ryRJkiQ1S69GPnhm3gzc3O66E2aw7eBGxiJJkiRJjda0JheSJEmSNLcxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6McGSJEmSpDoxwZIkSZKkOjHBkiRJkqQ6aWiCFRFbR8QTEfF0RAzv4PajI+KxiHg4Iv4SEcs1Mh5JkiRJaqSGJVgR0QKcCWwDrAHsFRFrtNvsn8DAzFwHuAr4UaPikSRJkqRGa+QI1gbA05n5bGZOAi4DhtRukJm3Z+Y71cV7gWUaGI8kSZIkNVQjE6ylgdE1l8dU183Il4H/6+iGiDg4Ih6IiAdeffXVOoYoSZIkSfXTJZpcRMQ+wEDgxx3dnpnnZubAzBzYv3//ORucJEmSJHVSrwY+9vPAsjWXl6mue5+I+BxwPLBpZk5sYDySJEmS1FCNHMG6H1g5IlaIiHmBPYEbajeIiHWBXwE7ZuYrDYxFkiRJkhquYQlWZk4BDgduAf4NXJGZj0bEyRGxY7XZj4GFgCsj4qGIuGEGDydJkiRJXV4jSwTJzJuBm9tdd0LNz59r5PNLkiRJ0pzUJZpcSJIkSdLcwARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6sQES5IkSZLqxARLkiRJkurEBEuSJEmS6qShCVZEbB0RT0TE0xExvIPb+0TE5dXtf4+I5RsZjyRJkiQ1UsMSrIhoAc4EtgHWAPaKiDXabfZl4I3MXAk4Dfhho+KRJEmSpEZr5AjWBsDTmflsZk4CLgOGtNtmCPDb6uergC0iIhoYkyRJkiQ1TGRmYx44Yldg68z8SnV5X2BQZh5es80j1TZjqsvPVNu81u6xDgYOri6uCjzRkKDnPv2A12a5lboS91n35H7rftxn3Y/7rPtxn3VP7rfOWy4z+7e/slczIpldmXkucG6z4+huIuKBzBzY7DjUee6z7sn91v24z7of91n34z7rntxvH14jSwSfB5atubxMdV2H20REL6AvMLaBMUmSJElSwzQywbofWDkiVoiIeYE9gRvabXMDsH/1867AbdmomkVJkiRJarCGlQhm5pSIOBy4BWgBzs/MRyPiZOCBzLwBOA/4XUQ8DbxOScJUP5ZVdj/us+7J/db9uM+6H/dZ9+M+657cbx9Sw5pcSJIkSVJP09CFhiVJkiSpJzHBkiRJkqQ6McGS5mK1C3e7iHf34b6SZi0iPIaR1CX55STNpSIiWrtyRkQvO3R2DxGxKLB59fNmEfGpJockdSkRsTpAZk4zyeo+IuJjzY5Bc15PPWHoF5PqpvVDVK1p1npdS/Mi6tlqkquhwJkRMU9P/aLrZuYHPh8RtwMnA080OZ4eKSL6RsQC1c/L+dnpGiJiPeBfEXEemGR1FxGxDHB8RHyp2bGosWqOBdeLiPl76sldv5RUN5mZEbEDcHZE/Coi5s3MqSZZzRMRRwJ7AKdl5jTKkgnqgloPEjPzBWA8sC7wcGa+XXu7Gq9au3ED4JCI+DYwjJL4qvleBv4FDI6Ii8Ekq5t4C3gSGBARezc7GDVOdSy4DXA18Mkmh9M0fiGpbiJiADAC+D9gAeDBiOhjktUcEdEHWI2yvlxGxJeBWyJik+p2z8h3EVU557Tq5zWACyj7rVdEnAptB5GW2MwBmTkJeAH4InAIcHFmvuP3WPNl5hjgp8APgbci4trqepOsLigilo2I/pk5jvK99giwUUTs09zI1CgRsQpwGrBzZt4TEStExNLViasewy8j1UVErAUcAVyfmddk5r7Ag8C9rUlWcyOc+7VPmDJzIjARuJJyQLIQ8BAwNCJaeuqwfVdUU855OHANMJmySPv5wFIR8d2I2AP4ekQ4ktIg7T5DjwF/o5ww2i4ilvV7rDkiYouI+HZEzFslUc9QTkD8CHglIq4Gk6yuJiIGAv+hnNjbExicmecBjwIrR8R+TQ1QjfRnYLWI+D5wKXAxsGFzQ5qzXGhYdVElWCcACZyUmY9V118BrAO0Tkr2F67BIuJQoC/QOzO/FxEbAk9m5usRsQVwDLBnZr7Z1ED1PlV57Qhg28x8OSJWAMYBKwBfA9YDvtj62VLjRMRRwKKZeUJErAvsDUwFhgPrAy2ZeU8zY+wpqjm9DwFrAD8A3gF+BewOLAz8Gjgd+GhmbtWkMDUDEXETsC3wFcrn6AmgN/AasCRwY2Ze3bwI9WG1NtSKiKWAyZn5apVYLQdcC9wEfBuYkJk/bGasc1KvWW8iTa/mAzWgumo8cBDlD92QiJiWmY9n5u4RMcDEas6IiK8Bu1LmjPwxIiZm5o+r244B9gX2M7lqvtouj5UELge2jYjlgP2B2yknLL4cEYtl5uvNiLUnqZKrXSmlgVAO7oNyQD8SWALwQH4OiIjPAh+nvN9/AD4G/Am4AXgAWCkzf1iN/P44IpapSgjVRBGxKaU8bFhmbh8RfwB2yswtImJ9YAdKp9SNgeUj4o+tc03V/VTHgttRmjI9WjUH+iIwpRpVHkDZ50c2M845zaF0zbaImKf6QG1NGfY9jFJGswNwFPAJYM9qLgnAw82JtGepSmNWBbYHtqAcgJxWU1L2HrBXZro/mqw2uYqI/hGxCHAvsDbweeBuYCNgPmAtAJOrxqs+K2sBuwDvRcSBwFWU0avTgJ8DO2Tmf5oWZM8yH7BHZj4PHABsSimf/TJlJOS1iFgpM8cDh5hcdRlPAF+KiB8DZOZ2wKIR8X+ZeX9mnkA5YbE+cJDJVfdWJVDHAztRSgM/BcxfJVcbAr8ATsjMkU0LsgksEVSnRcTiwPjMnBJlrZ4bgRMz8y9VMnU75Q/fv4ETgRGZ+WzzIp67tR8BqUppfkcpm3kL+FJmvhcRRwDPZObNTQpVM1CNlmxBmR93DXBWZk6pbtsOOAnYNTNHNS3IuVgHo4hExAXAisCbwB2U8uZ5MvNLcz7Cnq0qkz2L0gX1TxGxEfB74JTMPD/K+n5TmhulOhIRSwJ/B67JzGHVdbdTRjW2bGZs+vDanSRcmTK/aipllGqvzHw2IjbIzPsi4hOZ+UxH37dzM0ew1CkRsSBwILA0QGa+ATxHmWxMNS/ka8DWmfkMcLjJVeO0+3LbKspitEtTSjS3AM6rkqt9gENxLaUuobaJQkTsTpmbsCPwFGXkcWp12xcpNesHmFw1RrvP0Bcj4rCI2DczDwCOo4yI/JgyQXuxiFi4mfH2FBGxUOvPmfkc5UTeDyJiqWre257ANyLiGJOrriPKouj3R8RBEbFhZr5IWWpim4j4GUBmbgb0i4jrmhmrPryqimnTiNgLmET5zvwG8NkqufoMcGr1uW09TuwxyRWYYKnzJlI6mk2JiG9VB4pvUiYb11o8Sivjt+Z0gD1JzYHhUOA7wGeBPwIvUubCnVOdiT8c2L31C07N0+6AfnHgeeC7lD9KHwe2q/5orUSZb7JrZv6raQHP5Wr2xaGUOYu9gX0j4s+ZeXdmvhARRwM/Bo7PzAnNi7ZnqH73T473t/A+G7iPaj2dzLyfUi74xaq0Vk0WEb2BlYFlgP2A30dZXmJfYAjw5Yj4BkBmrksPm4szF5uf0jTrJUoDmqWBLSPiEP438vxCE+NrKptcaJaqOVdTgLERsSWwCnBoZn4tIq6OiNuAv1Imhh9rK+PGqJLa2vWSVqB0nPt0RHyPMgryfGb+virFmAqQmS81LWi1aXdAPxi4i/LH6YHW7mfVH6bPAgdW80rUQNWB4ebAUZn5N+CMiLguIs7PzAMppZt7Zea/mxpoDxBlYdL9KGVlI6pR+Qcz8+KIeJpSQXEzQGbeGxEbZ1mKQk0UEZsBrQ0O5gUWpDTsuZ3SdXMx4FXgh1GWbPmecxi7p/Ylfpn5x+qYcIPM/F2UtTc/S1kH9ajMvLWnlQXWMsHSTFUfjmkRsTmle9ZllN+bIRHx1czcJSJ2onygDs/Mv/bkD1SDzZeZ7wJExGBgGvBkRBxHObu7WzU/bg/gThOrrifKIs9fAHbJzAlR1on5RERsAHyacmZ+Tw8cG6OD76aplPKW2gWch1OdYc/Mk+dgeD1WRGwPfI8yEf6GiLgE2AfYISL2pxy8HxYRu2XmldXdJjUpXPG+z9JiwLTMfDMifk+Zh70U0Lc6PliQMgK5NWWeqbqpqsJiY0qH24uA+ynrBZ4EbJ6Zv+noPnM2yq7DEkHNVPWB2gn4GTCu+rD8mbJ47doRMRz4Q2Zekpl/bb1P0wKeS1UND86vft6VchD4IKUs4/DM3D4z342IL1Hmwnnw0QW0zrmKYjHKKO9ywOcAqsYJ91TXr0Mp53y0OdHO3dqVaA6uRkiWAX4DnBul2xWU7o0rR8SCtXPm1BgR8THKSO7BVXK1QGa+AlxNGdH6IyXZWpFSftQC/p3pAlpP0C8CLAqQmeMo65KNAXaMiCGZ+XZm3gQMS9fw65bafQ8+BLxOOVF4M/BPYN4oSyq0djMWjmBpFiKiL3AwpQX7ixExCBiUmWdU5TU7UeaPOMenQSJiK8rZ3QOriaNfoDSxeDsivk6Zs3Ad5YtuR0r3wNeaFrCA6UZL5s2y0PN3KO3y14+IVzPzrsz8ZrW9HdEaqCa5+irlO+0uSpORfSlrtvw6Iu6nTMzfJ20dPadMpLRefzci5gO+WX3P9QEeocyPC8rB3FOWoDdfRPQDHojSnvsV4COtt1UjWRdSkuLtIoLMvJ6qZF3dS+vfsSqBWgIYk5nHVbcdQfn+XINykvCO1ikMsk27OlDzgepLaVYxktKFbl7gbcqij9dl5tER0c+D+caJiM9TyjJ/kZknRsTOlOH4a4DvZ+ak6qDkq5QGFw9m5pPNi1jtVY1INgf6AmdQ1rs6vLr5lsy8o9rO0toGi4hPULoC7pGZz1UH8tdS9s9rlEYXU7Ksu6Q5oDo7fjRl/bc1gVspye+/KJ+TKzLzxuZFqI5ExI7AKcCplJHgiynHCy2ZObb6rG1D2X+vNC9SfVgRsQOlTPdCSrfbOzLzu9Vt8wErAZdTut7e16w4uxpHsPQ+NcnV1pQvx6Mp80IOBa7PzDurs1ZHVxNWTa4apCoLPAX4LaU7466ZeVVEvEspEXw4Im7OzPcoJZzqAiJiGcp6cRMiYhdgb0qp08qUBOtY4EeURHnTiLgvM98zuaq/iFifUr40pipPegN4mnLWner77LvA9pn5/eZF2nNVf29+RVlce1nK35mJABFxMKUETV1MVc75HqWEcyKlxHkNoFdEvEbpLHdw2n2zW4uI5YDDKFVMgynfpwMj4geZeVx1/PFIRPyVchJRFRMsvU/1x25zynpKB1TlGE8DXweoGUH5thPxGyci5qU0rvhaZv4tSne5IRExLTOvqbr1HEGpfb4mM51z1QVUSfGhlFb5EyjNX/6cmU8AT0TEWMr8xU0obWzfqP5Aqc6idKX7MWXh8wkRcVJm/qcamT+XkvhC2Uf9mxSmgMx8izIX8Z7W6yJiN2AAYOLbRWVZ/HlTyrISR1JOYKxCmaOzgMlV91ONPO4M/IMyivwaZd8uSTkOHAIMoqxx1SszvxERKwKrAv9tTtRdkwmW2lSTh4NSS/sz4N6I2JsyIf+/mXkipd7229XZK0uaGqQq/ftRZk6uLv8qIqYBO1U17ddUSdh+wE3Y1KLpqrlyJwPfzMyXqsm+bwOrRMS8mTkpM++JiJsoBx+2/m6QagT+58COmflERFwDDIiIlzNzu4j4U0TcADxLaSu890weTnNQRCwJ7EE5SbFHuoZfl1aNAu9JmUqwhd9r3VdErEopoX6YchLwt5l5HfBUdfLwmuok1dqUaQqXV3d9jtIZd9ycj7rrcg6WassCa8sDf0Ypo7kbeBzYDdgLmFp1qzO5mkOirEPWuvbVQcDGwJ8y89KIWKg6+6smiojVKKUy38rMS6qyiqMoq9tfQlmU+xJKQ5ijgK0yc3Sz4p2bRcRCwGnAkpm5fXXiaBTloOEd4J+Z+f2IGEJppPDPzHyqaQHrfSJifsqcuCcy8+lmx6POqT5PI4D1bHTQ/VSjUH8Bhmfm5VUDreWBX1AaMy0CXE/pZnwYZX3AkRHRYuOZjplg9XA1SdXmlI5a91MORt6gTPZ+tjpbcT4wJHvwqtzN1C7JOoIyGfwblmB0DVVHzd9RFnu+mVKa9ofM/EF1+w8oFQOrAMfZrrgxIqJ3Zk6u5onuRJnTsx5wemZeGGUNl2OBU5yMLdWXJ/y6p6rRzN6U7qrHVpUWd1EqY/4D9AMOAT5BaWjx38z8S7Pi7S5MsNTaqe40ytmnIymjVsdWiddWlFKbYzPzhqYFOZerHRGszrhPq97/trND7bZZxOH4rqF1H1Xz4s6ljDD+LjtYpDYi5nPOVWNUJ4kGA3/PzD9EWbz5AGA1SqnghGq7yymlLzc3LVhJ6kIioj+wHaU0cGPghsw8LiKWpXQpHpuZP2lmjN2NC4L1UNUZi9ZyjPUpJYCjKRO+T68O7pehtC0e2jrnqmkBz8XaJU5HAmcDp1VnA6dGzcKarfvA5KrrqPbRPFXTl69Q5iIsEhHLVPOwahdqtDFMA0TEtsAPKesmjQaoRqjOpLTFHxERC0TElpRujo83K1ZJ6moy81VKs5J7gVcpJ9qpStknUKoBNBscwerBqoON+SndX3ahNLjYOTNfiIjtKfMTrk8XP50jqjPwp1T/dqCUAW6dmW+Fi9B2ee1Gsn5DmXf148wc1dzI5m5RFj//PWVx4L/XXP954DZgRUozmE0pLYZ3t0RTkqYXEYtRyqsHAVcDLwAXUeZm/amJoXU7jmD1UNUchQMpi9PeAIwDLquSq0HATyhr+XhQPwdUE4S/RllQ+KbMPIQyKf/miFjY/dB11I7kto4uQttIVq9qJOvLwNLAERFht9bG6g+cl5l/b90fEfFjyppjv6HMKb0MeBCTK0maTmu1RWa+DtxIWTLhCOB2SufoP1nFNHtMsHqYKPpRhoFbMvN+yoKAV1IWjxtJWZ/nG5l5a/Minbt18EX1POVAcaOI+AhAZn6VcnB4lV9sXUdNOeeBwHkRsV1ELFrdNqVKsiYBuwM/NTlujIjYPCI2Aj4KfB7aktw1KWu2bAu8BQzLzEco7fNNriT1aDVTRFaPiOUjYunMnFYzHaG1XPAGykmpm6vrLXmbDZYI9hA13QIXzcw3ImIXynoHQzLz/6KsqdRCaSP9TmaOthV7Y7Sbc7Uppb75RcoJj4soX2oXZOab1TYfy8yXmhWvinadHLcBvg1cQTmQvx64sbX1uq1rGy8iTgL6Ukpqf0JZl+XG1gOFKtk6Buidmac2M1ZJ6kqqv2E/oiwfciiwafty9tapCR4LfjCOYPUANcnVIODyiNg+M6+mtOW8IiK2zrII6ruZ+UTrQaIfqMaoSa6GUg4Mv0YpYdoA2J9ywH5YRCxcbW9y1WTVZ6g1uVoTWBg4MTNPB34KbARsH2X9K0yu5oi/Af2qs61PAJsBO0PbSNaewI6UxEuSeryqimlF4ARgCKVKZhxltL9tGygVGdX/Hgt+AI5g9RDV2YpDKIvFrQh8paqp3ZkykXHbzPxjE0Oc60XEUsAr1Rmh5SijH0MoHXvWBc6htEOdTGmZ/6XMfKNJ4arSbsTxa8C3KGuDLJiZA6rrt6DUq/+BMvpoWWADVO/z6sA/KZOvL6GUB/amzHtbq7p9JCW52rUqD5SkHqvd37GFKCd2nwW+TmkQ9FREbAfc7XFHfTj5ugeIiKWB7wFfy8x7I+Jw4IQoi3JeGxF7AGbaDRQRH6fMyTknIt6hlAVOoKwtMRV4IMr6PBtm5hkRsYfrJXUNNX+UPkNZI+RTwHjgVxFxA6Xz5l8iYirwpMlVQ81Lef+3BBakrHF1NHAnpSX7vMBWwBjgLDs4SlLbMi8bAgdV/3ajLBzcrxrx3xD4RnWbCVYdOILVA1RdzC6idKi7p7ruJ8CewC6trY2ts22cah8sAKwAfCozL4iI3wMLZ+aQapsTgMUyc1jtfB81R01p7TzA4pT1yZYCjsjMByNiAeCXlD9Sm7m/5qyIWIEy/2rh6t9rQD/K99zVzYxNkpqt5m9Y6/8LUyqWjqRUyvyJUgXwEqUCYERmXt+8iOcuzsGaC9V0iOkfEUtVZ9RfBjaMiI9Vm11FOct7bk3XOpOrOqutZa6aVmxC6RS4E3AwMCEi7o6IkylnlM6ptvdgvYnanWxoqeb5DKPM9dkiIj6Rme9QygIfpbRk1xxQ0074OeB+4LXMHEzZFxcADzUtOEnqAqoGFa1/w1qP9d+ljPZ/PjOfBj5HWe90QUrn6OvtWFw/jmDNpSJiR8pw73jg/wE3Ad+ktAOfAmxOKVk7hrIY6pNNCnWu1a7r3B7A65Q1JQ4E1gFGZuZVEbE7ZZHnf7ofmq9drfqhwBaUP0xXUJY3+CklqbrO/dVc1VzGUzJzn2bHIkldQUT0B/ahVF0sA1wHHA78C1gMuBXYs7WiSY1hgjUXioh1gdMpHbX2BQ7KzDWruVgDgTUorcD7UUZMNrNTXeNExNeBXSiNRR6NiN7AF4ENKZ3QLs/Myc2MUdOLiL0po1ZHUdZaOhc4jHIG8CxKI4Wz3XfNExGLAHcDB7SWOktST1Z1un0XeAeYRGmmNZDyd+wiylSFhYEfWC3TODa5mAtExGKUEZB3q7KlFsqHaAdgj+p/KPN9rgeuj7JA53nATiZX9VW1QJ1crSW2ErB9Zm4UEQtFxFbAypn5y4joA6xNSXY9SG+yiFid8ln5adV4ZBHgt5l5V3X7aODXlHbgJ1M6Qrrfmms8ZQ7B6GYHIkldQXUidwHgRGAh4DjK9+QGwA+A+Skn2E+npj276ssRrG4uIlajLBj8OLAkJaFalHKGfT5gt8x8PiI+T2n9vWtmvlCNonysdc0r1Uc1ifQY4DTKGaRelImkLwNjKbXQmwAXU77oFs7McU0JVm2irGC/LeVM378p++/LlFXst6zZ7kLgpGr+j7qA1sUwmx2HJDVT+0ZlEfEpylSQ3pTmP6Mioh8wAJiSmX9tUqg9gglWNxYRq1DOSvwS+CMwHKDqQvcdSivjH1M6oH0dGJ6ZN9mhrjFqOvX0AdaklAX+ktI98GDKaMhj1dpj62bmCU0MV5V2c+UOAzYFbqk6Pd5EGR0+CtgYGArskJnPNy1gSZJq1Bx/bA6sTDmpe2P18wGUk7tnZ+az7e/TlIB7ABOsbqqm9fpCmbljdd2awFeAb2bm5IjYl9JCemngymphYT9QDdCuMcIiQH/KiOEjwPmZ+XJ12+GUdSb2dgHUriUihgHbARMpI4/XZOa5EfFLyhnATwBHZuajzYtSkqTpRcQOlOOOc4EvUJoxHQssT1lYGMqJdtfYnANMsLqxas7Izyjd6H4YEcdQ1oW5k1Im+AvgcSd/zzkRcRCwdmYOjYi1KYugPgFcD4wDzgBOzsx/NS9KtRcRywCXAVtk5sSqC+fOwF8y8/fVNgtUcxwlSWqqqtxvqcx8uFqC5xeUKQqDKF2jnwAmUJawWImyGs8TzYq3pzHB6qZay5qqJOsMymTv5Sjd6V4F9qactbjKBGvOiIj9KAnVLpn5THXdOpSyshcoDRJezsxJzYtS0GGt+rKU1rX7ZOb91QThU4FPU0Ygf+norySpK4iIeSml68sCv87M/1c12PoIZT3AnSndAs+jnIQ/sGnB9lAuNNxNVcnVPJn5b+CrlIYWt2XmU5k5LjPPBL5tctV4UfQCPgWcmJnPRESf6oD8YUrDhMUpXR5NrpqsXTnnShHxkarZy9nAvhGxTjVS9ShwB2VRbhfiliR1CdWxxEiqE+oRMaCaX7Ug5VhwFOUY/1rKXHDNYY5gdUMR0VK1ka4dyVqNciB/L6VbzOtNDXIu19FoRkR8i2ruVWaOr64bAtxPaeltp7Mma5dcDaOM9PamlFW8RRmxOhi4Bdge2NrFhCVJXUFVbbF6Zv6purw8Ze59L+By4A3gdkpitTelKuPPzYm2ZzPB6iZqOsR8lrJY3E2tExVrkqw1KeWCB9V2ilF9tTtI35oy3+1eygLOWwL3AX8BPgscCexlO/yuJSK2BQ4B9gT2o+y3C4G/UlrYfgz4Z2uppyRJzVSVBT5FVRYIvAJcQ6lg+jTQlzIvf3FKJ+PXWtdx1JxngtUN1CRQnwfOAfZr/6Gp2WbBzHy7OZH2LBFxBLAX8Ofq//2A1YD1KMlWCzC0KhNUFxERK1PWIOuTmTtU1x0A7Eg5A3hl6wixJEldRUQMAG4A/gmcDxxPOam7BmWtzXcoVTSjmhWjCudgdWER0R/a5lstDBwGHJ6Zd0XEPNU20bpNdTe7nDVQ6/sdEatSRqg2AZ4Hns/MezPzQsrE032BnUyumq91n9V4kZJIzRsRhwBk5gWUssAhlFXuJUnqUjLz/1FOBm5KGSQZBPwceJpSTbMfsHDTAlSbXs0OQB2rFqs9PCJ+m5nPZuaEiHgZaE2kWqqfV4qIlzJzAjgRv1EiYlFgErAQZQG//1KaIPyOMu/qc9V2XwZuyMwXmhSqarQr59wTeI/SbOTKKu/6fLXJuZl5TkRcmplvNTNmSZJmpOoYuBXwp4g4LjPPjojDqpPxK2Tmc82OUY5gdWVTgR8D70bET6vrXgF2jYh5q4WE16U0tujbrCB7gmq+zoWUtayurppZTAYWA1YEDs7MqRHxRcqcK0dAuoia5OpI/rdvfhERB2TmlcAfgc2rEkGAN5sTqSRJnZOZ91FO7J4UEcNqqphGQYeVG5rDHMHqYiJifmC+zHyjdRE54OMRcWxmnhARlwCXRsQblLk+J2fmmGbGPDer5r39iLKW1SuUFqjXAUlJgH8GfDciWoC1gC9m5n+bE606EhGfArYBNgO+AfwHODYi+lSjVlMoNeyOAEuSuoXMfCAidgBujYhrgNGtf8P8W9Z8NrnoQqozDhsAuwJPAp8BvkPpCHMM8HBm/jAiNqJ0EnyhWhTVBVAbICI2p4xafbJa26p3NXL4CeAeysH6lcDawBLAQyZXzRcRn6bsk+eAv1HmJX4U2Bg4KjM/HRGHUTpuHpqZ5zUtWEmSPoRqLUerL7oYSwS7kCpJegT4OGXU5JbM/A/wGKUUcM2I+FFm3pOZ12fm/TX3U/29BixAWUAYYEpVnvkMpb33PkCvzPx7Zt5gctV8VV362ZTmI/sCwwAy80XK6OPV1aaTge9T2rJLktRdTQDLArsaSwS7iJpRqHeBhymLnm4bEQ9k5hPAAxFxFvCViFg9M//dzHh7gsx8OCIGAX+OiH7VRNIpVTngO5R9ZUv8LqIacbwSWDUzX6xKJ7avabn+LrBDRKxI6cL02eoEhiRJ3ZJlgV2TCVYXULOI8E6UuSJDKQvHDQNOqTrTLQgsD3w9M8c1J9Kep6px3pKSZEVmngUQEatRkqt5KQfuar7XKJ+TzYBLMvPGiDguIo4FHq06B75NaXRxlsmVJElqBBOsLqBKrrYBTgS+kZkTI2IS8CvgAMpCtosBB5hczXntkqxXgTcoye8+mWly1UW0G3HsAyxJSaYGABtFxM8pTUnOzcwpzYtUkiTNzWxy0SQRsSSwR2b+vLp8CnAvZXXuQcBewEXAnZTGF29l5t+aE60AImIgpdvcK8Bmlml2TRGxPvAn4I3MXLHm+h2Af9p1U5IkNZIJVpNExKqUJiPjqvkiQylrGiwG3Eg5+74Y8FUXPu06ImINYGo1L05dVESsQ2lgMTQzf9fseCRJUs9hiWDzPAn0Bi6IiBcy8xsRcRcwITOfioiVgIsp7b9NsLqIzHys2TFo1qpywS2B+yKiV2Ze0OyYJElSz2Cb9uZZPjMnAT8EloiIH2TmP6rkamfKYrbfr1qCS5pNmfkAZTHuu5sdiyRJ6jksEZyDaroFrkwpA7ygWjh4TeBY4KXM/GZEfLH6+TYXEZYkSZK6DxOsOSwihlAWQH2bsoDt5Zn5vWpuz8nAk5n5rWbGKEmSJOmDMcGagyJiEUrL9aOBvwFrA2cD12bmjyNibaB3Zv6jeVFKkiRJ+qBscjFnTaUshvpsZk6LiEeA3wPHRMTbrYvYSpIkSeqebHLRQBER1f9LRUSfzJxAWevq6oiYPzOnAv8Fbga2qeZiSZIkSeqmHMFqoKqhxdbAicBTEdECfAtI4B8RcR4wlDIna28gmhasJEmSpA/NBKuBqm6BPwcOAl4GdgIuAbbmf+tgbQMsDAwE3mxGnJIkSZLqwwSrztq1VZ8K3JOZd0bEPJn5o4hYDtgxMy+utl+fkoQdkJn/bU7UkiRJkurBOVh1EhF9oa0ssLXUbwLw2Yj4WmZOq64bC3ys5q6vADtl5v+bc9FKkiRJagRHsOogIvpQ5lT9MjNPq5Ks3pn5akTsBlwaEUsCDwA7AsNa75uZ/2lO1JIkSZLqzXWw6iQiNgKuB07IzHOq63pn5uSIWBb4LvA8cG9m3tjEUCVJkiQ1iCNYdZKZ90TEtsCfI4IqyWotC+xNWWD4ktYSwjSzlSRJkuY6zsGqo8x8ANgS+EFEfDUzp0bEYOA+4OXWpMrkSpIkSZo7WSLYABExkLJ48LXApsC3MvOa5kYlSZIkqdFMsBqkar9+G3BgZl7Z2lnQ0StJkiRp7mWC1UARsVBmvuWcK0mSJKlncA5WY73d7AAkSZIkzTmOYEmSJElSnTiCJUmSJEl1YoIlSZIkSXVigiVJkiRJdWKCJUnqdiJi+YjI6t93aq4/r/X62Xy8Rzpzn4gYUT3+rh8kbknS3M8ES5LU3X0pioWA3ZsdjCSpZzPBkiR1Z88CKwKDKclVb+B5gCrp+nZE/CciJkTE7RGxZnXbIhHxh4h4OyJ+V92vTUQcFxHPVfe7JSJWnKOvSpLUbZlgSZK6s38DfwcOrP5dB4yrbjsA+C7wMHA8sD5wfUT0Bk4EtgUuBv4LrNL6gBGxP/D96nFPBdYBrmz4K5EkzRV6NTsASZI+pPOBM4A+wNbAT6vrt63+Pzozn4qIQcAXKcnUYGAacHhmToqI/YBlqu23r/7fo/oH8LGIWKyhr0KSNFcwwZIkdXeXAacBY4A/d3B7tvu/s/YGXql+ngd45wNFJ0nqUSwRlCR1a5n5JqU88JDMnFZz0x+q/38WEUcAQ4BngCeB2yl/A38ZEafwv9ErgJuq//cHlgU2Bb6Tme817lVIkuYWjmBJkrq9zLy8g6svBJYGDgI2B+6nlAROjojvAqtRSgD/D3gaWKl6rN9GxMeAQ4CzKSNjHT2+JEnTiczZrZiQJEmSJHXEEkFJkiRJqhMTLEmSJEmqExMsSZIkSaoTEyxJkiRJqhMTLEmSJEmqExMsSZIkSaoTEyxJkiRJqpP/D2ZE58G3ImxuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_model_accuracy(results):\n",
    "    # Extract model names, training accuracy, and testing accuracy\n",
    "    model_names = list(results.keys())\n",
    "    train_accuracy = [result['Training Accuracy'] for result in results.values()]\n",
    "    test_accuracy = [result['Testing Accuracy'] for result in results.values()]\n",
    "\n",
    "    # Set the width of the bars\n",
    "    bar_width = 0.35\n",
    "\n",
    "    # Set the position of the bars on the x-axis\n",
    "    r1 = np.arange(len(model_names))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "\n",
    "    # Plot the bar graph\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(r1, train_accuracy, color='b', width=bar_width, edgecolor='grey', label='Training Accuracy')\n",
    "    plt.bar(r2, test_accuracy, color='r', width=bar_width, edgecolor='grey', label='Testing Accuracy')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Model', fontweight='bold')\n",
    "    plt.ylabel('Accuracy', fontweight='bold')\n",
    "    plt.xticks([r + bar_width/2 for r in range(len(model_names))], model_names, rotation=45)\n",
    "    plt.title('Accuracy of Different Models on Training and Testing Sets')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage example:\n",
    "# Assuming results is the dictionary returned by evaluate_models function\n",
    "plot_model_accuracy(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb2cef",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning¶\n",
    "- GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "025c04cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Accuracy Score: 0.833843537414966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t5/961m25k976xdp4w3m8b1r5600000gn/T/ipykernel_66725/2628549244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Accuracy Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy Score on Test Set:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'],  # Penalty norm\n",
    "    'solver': ['liblinear', 'saga']  # Optimization algorithm\n",
    "}\n",
    "\n",
    "# Create the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy Score:\", best_score)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Score on Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bac80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Just rounding them so the numbers are easier to read\n",
    "cm = cm.round(2)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confusion Matrix of Heart Disease For Logistic Regression\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "print('true-negitive:', tn, \n",
    "      '\\nfalse-positive:', fp, \n",
    "      '\\nfalse-negative:', fn, \n",
    "      '\\ntrue-positive:', tp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea82b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d97103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Train logistic regression model with best parameters\n",
    "logistic_model = LogisticRegression(**best_params)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_probs = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Calculate area under ROC curve\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f475783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166901a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=0.1,\n",
    "                        solver=\"liblinear\", penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validated accuracy\n",
    "cv_acc= cross_val_score(clf,\n",
    "                       X,\n",
    "                       y,\n",
    "                       cv=5,\n",
    "                       scoring=\"accuracy\")\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d78eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_precision= cross_val_score(clf,\n",
    "                       X,\n",
    "                       y,\n",
    "                       cv=5,\n",
    "                       scoring=\"precision\")\n",
    "cv_precision = np.mean(cv_precision)\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfa381",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_recall= cross_val_score(clf,\n",
    "                       X,\n",
    "                       y,\n",
    "                       cv=5,\n",
    "                       scoring=\"recall\")\n",
    "cv_recall = np.mean(cv_recall)\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_f1= cross_val_score(clf,\n",
    "                       X,\n",
    "                       y,\n",
    "                       cv=5,\n",
    "                       scoring=\"f1\")\n",
    "cv_f1 = np.mean(cv_f1)\n",
    "cv_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({\"Accuracy\": cv_acc,\n",
    "                          \"Precision\": cv_precision,\n",
    "                          \"Recall\": cv_recall,\n",
    "                          \"F1\": cv_f1},\n",
    "                          index=[0])\n",
    "\n",
    "cv_metrics.T.plot.bar(title=\"Cross-validated classification metrics\",\n",
    "                      legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d32a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=0.1,\n",
    "                        solver=\"liblinear\", penalty='l2')\n",
    "\n",
    "clf.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce947162",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = dict(zip(df.columns, list(clf.coef_[0])))\n",
    "feature_dict\n",
    "\n",
    "feature_df = pd.DataFrame(feature_dict,index=[0])\n",
    "feature_df.T.plot.bar(title=\"Feature Importance\",legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65781ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base on the visualisation,\n",
    "# chest pain type(cp)\n",
    "# resting electrocardiographic results(restecg)\n",
    "# slope of the peak exercise ST segment(slope)\n",
    "# have strong feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420539aa",
   "metadata": {},
   "source": [
    "To address this issue, it's essential to interpret the results of grid search and cross-validation in conjunction with each other. While grid search helps in selecting the optimal hyperparameters for a model based on a specific dataset or subset, cross-validation provides a more reliable estimate of the model's generalization ability across different data partitions. It's essential to consider both results when assessing the overall performance and robustness of the model. Additionally, further investigation into the specific characteristics of the data and model behavior can help in understanding the observed differences in accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae27f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing it out for one model now doing it for the rest but feature importance should be for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19698104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the decision tree classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy Score:\", best_score)\n",
    "\n",
    "# Train the decision tree classifier with the best parameters\n",
    "best_dt_classifier = DecisionTreeClassifier(**best_params)\n",
    "best_dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = best_dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set - how well the model generalizes to unseen data\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Score on Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c44979",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Just rounding them so the numbers are easier to read\n",
    "cm = cm.round(2)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confusion Matrix of Heart Disease For DT\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "print('true-negitive:', tn, \n",
    "      '\\nfalse-positive:', fp, \n",
    "      '\\nfalse-negative:', fn, \n",
    "      '\\ntrue-positive:', tp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = grid_search.predict(X_test)\n",
    "\n",
    "# Train DecisionTreeClassifier model with best parameters\n",
    "descision_tree_model = DecisionTreeClassifier(**best_params)\n",
    "descision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_probs = descision_tree_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Calculate area under ROC curve\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve For DT')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182a13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179095aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bca7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini',\n",
    "                        min_samples_leaf=4, min_samples_split=2, max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b5503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scoring metrics\n",
    "scoring_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "# Initialize dictionary to store cross-validated scores\n",
    "cv_scores = {}\n",
    "\n",
    "# Perform cross-validation for each scoring metric\n",
    "for metric in scoring_metrics:\n",
    "    # Compute cross-validated scores\n",
    "    cv_scores[metric] = np.mean(cross_val_score(clf, X, y, cv=5, scoring=metric))\n",
    "\n",
    "# Print the cross-validated scores\n",
    "for metric, score in cv_scores.items():\n",
    "    print(f\"Cross-validated {metric.capitalize()}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Accuracy Score:\", best_score)\n",
    "\n",
    "# Train the Random Forest classifier with the best parameters\n",
    "best_rf_classifier = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy Score on Test Set:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a3a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = grid_search.predict(X_test)\n",
    "\n",
    "# Train RandomForestClassifier model with best parameters\n",
    "random_forest_model = RandomForestClassifier(**best_params)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_probs = random_forest_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Calculate area under ROC curve\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve For RF')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f127efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Just rounding them so the numbers are easier to read\n",
    "cm = cm.round(2)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confusion Matrix of Heart Disease For RF\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "print('true-negitive:', tn, \n",
    "      '\\nfalse-positive:', fp, \n",
    "      '\\nfalse-negative:', fn, \n",
    "      '\\ntrue-positive:', tp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth= None,\n",
    "                        min_samples_leaf=1, min_samples_split=5, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scoring metrics\n",
    "scoring_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "# Initialize dictionary to store cross-validated scores\n",
    "cv_scores = {}\n",
    "\n",
    "# Perform cross-validation for each scoring metric\n",
    "for metric in scoring_metrics:\n",
    "    # Compute cross-validated scores\n",
    "    cv_scores[metric] = np.mean(cross_val_score(clf, X, y, cv=5, scoring=metric))\n",
    "\n",
    "# Print the cross-validated scores\n",
    "for metric, score in cv_scores.items():\n",
    "    print(f\"Cross-validated {metric.capitalize()}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost classifier\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_xgb = grid_search.best_params_\n",
    "best_score_xgb = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters (XGBoost):\", best_params_xgb)\n",
    "print(\"Best Accuracy Score (XGBoost):\", best_score_xgb)\n",
    "\n",
    "# Train the XGBoost classifier with the best parameters\n",
    "best_xgb_classifier = XGBClassifier(**best_params_xgb, random_state=42)\n",
    "best_xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_xgb = best_xgb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"Accuracy Score on Test Set (XGBoost):\", accuracy_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = grid_search.predict(X_test)\n",
    "\n",
    "# Train XGBClassifier model with best parameters\n",
    "XGBClassifier_model = XGBClassifier(**best_params_xgb)\n",
    "XGBClassifier_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_probs = XGBClassifier_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Calculate area under ROC curve\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve For XGB')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ba908",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Just rounding them so the numbers are easier to read\n",
    "cm = cm.round(2)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confusion Matrix of Heart Disease For XGBoost\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "print('true-negitive:', tn, \n",
    "      '\\nfalse-positive:', fp, \n",
    "      '\\nfalse-negative:', fn, \n",
    "      '\\ntrue-positive:', tp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb80597",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04949739",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(colsample_bytree= 0.8,\n",
    "                        learning_rate=0.2, max_depth=5, n_estimators = 300,subsample = 1.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e3fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scoring metrics\n",
    "scoring_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "# Initialize dictionary to store cross-validated scores\n",
    "cv_scores = {}\n",
    "\n",
    "# Perform cross-validation for each scoring metric\n",
    "for metric in scoring_metrics:\n",
    "    # Compute cross-validated scores\n",
    "    cv_scores[metric] = np.mean(cross_val_score(clf, X, y, cv=5, scoring=metric))\n",
    "\n",
    "# Print the cross-validated scores\n",
    "for metric, score in cv_scores.items():\n",
    "    print(f\"Cross-validated {metric.capitalize()}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e02c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-Nearest Neighbors (KNN) classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best parameters\n",
    "grid_search_knn = GridSearchCV(estimator=knn_classifier, param_grid=param_grid_knn, cv=5, scoring='accuracy')\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "best_score_knn = grid_search_knn.best_score_\n",
    "\n",
    "print(\"Best Parameters (KNN):\", best_params_knn)\n",
    "print(\"Best Accuracy Score (KNN):\", best_score_knn)\n",
    "\n",
    "# Train the KNN classifier with the best parameters\n",
    "best_knn_classifier = KNeighborsClassifier(**best_params_knn)\n",
    "best_knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_knn = best_knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"Accuracy Score on Test Set (KNN):\", accuracy_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3984fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = grid_search.predict(X_test)\n",
    "\n",
    "# Train KNeighborsClassifier model with best parameters\n",
    "KNeighborsClassifier_model = KNeighborsClassifier(**best_params_knn)\n",
    "KNeighborsClassifier_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_probs = KNeighborsClassifier_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Calculate area under ROC curve\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve For KNN')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b566ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Just rounding them so the numbers are easier to read\n",
    "cm = cm.round(2)\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title(\"Confusion Matrix of Heart Disease For knn\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "print('true-negitive:', tn, \n",
    "      '\\nfalse-positive:', fp, \n",
    "      '\\nfalse-negative:', fn, \n",
    "      '\\ntrue-positive:', tp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776dd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25973773",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(n_neighbors=5,\n",
    "                        p=1, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43935b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scoring metrics\n",
    "scoring_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "# Initialize dictionary to store cross-validated scores\n",
    "cv_scores = {}\n",
    "\n",
    "# Perform cross-validation for each scoring metric\n",
    "for metric in scoring_metrics:\n",
    "    # Compute cross-validated scores\n",
    "    cv_scores[metric] = np.mean(cross_val_score(clf, X, y, cv=5, scoring=metric))\n",
    "\n",
    "# Print the cross-validated scores\n",
    "for metric, score in cv_scores.items():\n",
    "    print(f\"Cross-validated {metric.capitalize()}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1aeb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "param_grid_nb = {}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best parameters\n",
    "grid_search_nb = GridSearchCV(estimator=nb_classifier, param_grid=param_grid_nb, cv=5, scoring='accuracy')\n",
    "grid_search_nb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_nb = grid_search_nb.best_params_\n",
    "best_score_nb = grid_search_nb.best_score_\n",
    "\n",
    "print(\"Best Parameters (Naive Bayes):\", best_params_nb)\n",
    "print(\"Best Accuracy Score (Naive Bayes):\", best_score_nb)\n",
    "\n",
    "# Train the Naive Bayes classifier with the best parameters\n",
    "best_nb_classifier = GaussianNB(**best_params_nb)\n",
    "best_nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred_nb = best_nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"Accuracy Score on Test Set (Naive Bayes):\", accuracy_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e69def",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = grid_search.predict(X_test)\n",
    "\n",
    "# Train GaussianNB model with best parameters\n",
    "GaussianNB_model = GaussianNB(**best_params_nb)\n",
    "GaussianNB_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for positive class\n",
    "y_probs = GaussianNB_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "\n",
    "# Calculate area under ROC curve\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve For NB')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c68b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df4386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scoring metrics\n",
    "scoring_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "# Initialize dictionary to store cross-validated scores\n",
    "cv_scores = {}\n",
    "\n",
    "# Perform cross-validation for each scoring metric\n",
    "for metric in scoring_metrics:\n",
    "    # Compute cross-validated scores\n",
    "    cv_scores[metric] = np.mean(cross_val_score(clf, X, y, cv=5, scoring=metric))\n",
    "\n",
    "# Print the cross-validated scores\n",
    "for metric, score in cv_scores.items():\n",
    "    print(f\"Cross-validated {metric.capitalize()}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a19547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7353921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3619cb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826a36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
